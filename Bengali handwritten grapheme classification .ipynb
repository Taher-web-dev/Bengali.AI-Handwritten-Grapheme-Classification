{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\ntest=pd.read_csv('/kaggle/input/bengaliai-cv19/test.csv')\nsubmission=pd.read_csv('/kaggle/input/bengaliai-cv19/sample_submission.csv')\nclass_map=pd.read_csv('/kaggle/input/bengaliai-cv19/class_map.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n# create class which allow to data augmentation for multioutput. \nclass MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix='',\n             save_format='png',\n             subset=None):\n\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image , ImageOps\nfrom PIL import ImageFilter\ndef blur (img):\n    \"\"\" \"\"\"\n    image= Image.fromarray(img).convert('L')\n    \n    image=image.filter(ImageFilter.GaussianBlur(radius=2))\n    \n    return image\ndef contrast(img):\n    image=Image.fromarray(img).convert('L')\n    image=ImageOps.autocontrast(image)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.auto import tqdm\nimport cv2\nsize=96\ndef resize(df, size=96, need_progress_bar=True):\n    resized = {}\n    resize_size=96\n    if need_progress_bar:\n        for i in tqdm(range(df.shape[0])):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            \n            img=blur(image)\n            img=np.array(img)\n            image=contrast(image)\n            image=np.array(image)\n            _, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    else:\n        for i in range(df.shape[0]):\n            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                w=max(w,resize_sizee)\n                h=max(h,resize_size)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN architecture "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Dropout,Input,MaxPooling2D, BatchNormalization,Conv2D,Flatten\nfrom keras.models import Model\nInputs=Input(shape=(size,size,1))\nmodel=Conv2D(64,(3,3),padding='same',input_shape=(size,size,1),activation='relu')(Inputs)\nmodel=Conv2D(64,(3,3),padding='same',activation='relu')(model)\nmodel=MaxPooling2D((2,2),strides=(2,2))(model)\nmodel=BatchNormalization(momentum=0.15)(model)\nmodel=Conv2D(128,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(128,(3,3),padding='same',activation='relu')(model)\nmodel=MaxPooling2D((2,2),strides=(2,2))(model)\nmodel=BatchNormalization(momentum=0.15)(model)\nmodel=Conv2D(256,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(256,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(256,(3,3),padding='same',activation='relu')(model)\nmodel=MaxPooling2D((2,2),strides=(2,2))(model)\nmodel=BatchNormalization(momentum=0.15)(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=MaxPooling2D((2,2),strides=(2,2))(model)\nmodel=BatchNormalization(momentum=0.15)(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=Conv2D(512,(3,3),padding='same',activation='relu')(model)\nmodel=MaxPooling2D((2,2),strides=(2,2))(model)\nmodel=BatchNormalization(momentum=0.15)(model)\nmodel=Flatten()(model)\nmodel=Dense(1024,activation='relu')(model)\ndense=Dense(512,activation='relu')(model)\nconsonant=Dense(7,activation='softmax')(dense)\ngrapheme=Dense(168,activation='softmax')(dense)\nvowel=Dense(11,activation='softmax')(dense)\nmodel=Model(inputs=Inputs,outputs=[consonant,grapheme,vowel])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model,to_file='model.png',show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.losses import categorical_crossentropy\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n#Reducing learning rate when accuracy has stopped improving.\n#We will use a callback wich will control the accuracy and reduce learning rate by 40% when the quantity\n#controlled had not enhanced after 4 epochs \nlr_consonant=ReduceLROnPlateau(monitor='dense_3_accuracy',factor=0.4,patience=4,min_lr=0.00001)\nlr_grapheme=ReduceLROnPlateau(monitor='dense_4_accuracy',factor=0.4,patience=4,min_lr=0.00001)\nlr_vowel=ReduceLROnPlateau(monitor='dense_5_accuracy',factor=0.4,patience=4,min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfor i in range(4):\n    df=pd.merge(pd.read_parquet('/kaggle/input/bengaliai-cv19/train_image_data_{}.parquet'.format(i)),train,\\\n                on='image_id',how='left').drop(['image_id','grapheme'],axis=1)\n   \n    X=df.drop(['grapheme_root','vowel_diacritic','consonant_diacritic'],axis=1)\n    X=resize(X)/255\n                                                                                                   \n    X=X.to_numpy().reshape(-1,size,size,1)\n    Y_consonant=pd.get_dummies(df['consonant_diacritic']).to_numpy()\n    Y_grapheme=pd.get_dummies(df['grapheme_root']).to_numpy()\n    Y_vowel=pd.get_dummies(df['vowel_diacritic']).to_numpy()\n    del(df)\n    # Divide the data into training and test data\n    xtr,xts,ytr_consonant,yts_consonant,ytr_grapheme,yts_grapheme,ytr_vowel,yts_vowel=train_test_split(X,\\\n                                                            Y_consonant,Y_grapheme,Y_vowel,test_size=0.1)\n    \n    del(X)\n    del(Y_consonant)\n    del(Y_grapheme)\n    del(Y_vowel)\n    #data augmentation .\n    datagen=MultiOutputDataGenerator(rotation_range=10 # rotate the image\\\n                                    ,zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.15)\n    datagen.fit(xtr)\n    fichier=[]\n    #train the model.\n    md=model.fit_generator(datagen.flow(xtr,{'dense_3':ytr_consonant,'dense_4':ytr_grapheme,'dense_5':\\\n                                             ytr_vowel},batch_size=256),steps_per_epoch=len(xtr)/256,\\\n                          epochs=24,validation_data=(xts,[yts_consonant,yts_grapheme,yts_vowel]),\\\n                          callbacks=[lr_consonant,lr_grapheme,lr_vowel])\n    fichier.append(md)\n    # reduce memory\n    del(xtr)\n    del(xts)\n    del(ytr_consonant)\n    del(yts_consonant)\n    del(ytr_grapheme)\n    del(yts_grapheme)\n    del(ytr_vowel)\n    del(yts_vowel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ant=[]\nfor i in range(4):\n    ts=pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i))\n    ts=ts.drop(['image_id'],axis=1)\n    ts=resize(ts,need_progress_bar=True)\n    tss=ts.to_numpy()/255\n    tss=tss.reshape(-1,size,size,1)\n    prediction=model.predict(tss)\n    l=len(ts)\n    del(ts)\n    m=0\n    del(tss)\n    for j in range(l):\n        ant.append(np.argmax(prediction[0][m]))\n        ant.append(np.argmax(prediction[1][m]))\n        ant.append(np.argmax(prediction[2][m]))\n        m+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target']=ant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}